{
    "name": "Remote OLLAMA API",
    "image": "python:3.10.13",
    "onCreateCommand": "apt-get update && apt-get install -y curl git wget python3-pip cron lshw lspci psmisc lsof",
    "updateContentCommand": "pip install flask==2.0.2 && pip install werkzeug==2.0.3 && pip install requests==2.26.0 && pip install python-dotenv==0.19.1 && pip install llama-cpp-python && export OLLAMA_HOST=0.0.0.0:11434 && curl https://ollama.ai/install.sh | sh && ollama serve > /dev/null 2>&1 &> output.log &",
    "postCreateCommand": "ollama pull tinyllama && wget -c https://github.com/gali1/external-codebase/raw/main/text-gen-webui/main.py && wget -c https://github.com/gali1/external-codebase/raw/main/text-gen-webui/index.html && echo '* * * * * python /workspaces/external-codebase/main.py' >> /var/spool/cron/crontabs/root && python3 /workspaces/external-codebase/main.py",
    "postStartCommand": "",
    "customizations": {
        "codespaces": {
            "repositories": {
                "*/*": {
                    "permissions": "write-all",
                    "vscode": {
                        "extensions": [
                            "ms-python.python",
                            "ms-toolsai.jupyter",
                            "jupyter.jupyterlab",
                            "ms-vscode.remote-server"
                        ]
                    }
                }
            },
            "forwardPorts": [
                8888,
                9898,
                11434,
                8877,
                9899
            ]
        }
    }
}